{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805ba5c9",
   "metadata": {},
   "source": [
    "# File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1f7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concats all csv files in a folder and creates a now column to record file name\n",
    "\n",
    "def load_data(path):\n",
    "    all_files = glob.glob(path + \"/\".csv)\n",
    "    \n",
    "    #___rows to skip___ \n",
    "    # this skips the first row\n",
    "    #rows_to_skip = range(1)\n",
    "    \n",
    "    all_data = []\n",
    "     \n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, skiprows = rows_to_skip, encoding = 'utf-8')\n",
    "        df = df.assign(filename = os.path.basename(file))\n",
    "        all_data.append(df)\n",
    "        \n",
    "    result = pd.concat(all_data, axis = 0)\n",
    "    return result\n",
    "\n",
    "#path = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17681026",
   "metadata": {},
   "source": [
    "# Data Frame Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5737f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "\n",
    "def format_headers(df):\n",
    "    \n",
    "    # ____ comment out if no need to handle nan values in table header ____ \n",
    "    #the code converts df into series and then renames it with a cumulative count\n",
    "    s = pd.Series(df.columns)\n",
    "    s = s.fillna('unnamed:' + (s.groupby(s.is_null()).cumcount()+1).as_type(str))\n",
    "    df.columns = s\n",
    "    \n",
    "    #replace NaN with 0 and then drop columns containing only NaN\n",
    "    df = df.loc[:,~df.replace(0,np.nan).isna().all()]\n",
    "    \n",
    "    #rename the columns\n",
    "    df.columns = [x.lower().replace(\" \",\"\").replace(\"-\",\"_\").replace(\"-\",\"\")\\\n",
    "                 .replace(\".\",\"\").replace(\"/\",\"_\").replace(\"?\",\"\")\\\n",
    "                 .replace(\"#\",\"\").replace(\":\",\"_\") for x in df.columns ]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4417830",
   "metadata": {},
   "source": [
    "# Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f6be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "# output display settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"\"))\n",
    "\n",
    "#visualisation \n",
    "import seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1106b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table header and data type\n",
    "def check_col(df):\n",
    "    for col in raw:\n",
    "        print(col,type(col))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219d1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return percentage of null for each column in df\n",
    "def check_percent_null(df):\n",
    "    null_percent_df = round(df.isnull().mean()*100,2) \n",
    "    return null_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5768f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_percent_null(df):\n",
    "    unique_value_counts = pd.DataFrame(columns=['unique_values'])\n",
    "    for value in list(df.columns.values):   \n",
    "        unique_value_counts.loc[value] = [df[value].nunique()]\n",
    "        \n",
    "    return unique_value_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb4d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe numeric columns in df and print without limit/display constraints\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df.describe()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbbd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition out rows with index if they meet certain contitions \n",
    "df = df.reset_index()\n",
    "\n",
    "def partition_problematic(df):\n",
    "    problematic_df = df[ (df.col1.isna() | df.col1.contains(\"0\")) & (df.col2.isna() | df.col2.contains(\"0\")) ]\n",
    "    return problematic_df \n",
    "\n",
    "def partition_unproblematic(df):\n",
    "    problematic_df = partition_problematic(df)\n",
    "    unproblematic_df = df[~problematic_df].query( \"col3 != 0 or col4 != 0 \")\n",
    "    #delete query function if no \"or condition\"\n",
    "    return unproblematic_df\n",
    "\n",
    "def partition_mildly_problematic(df,problematic_df,unproblematic_df):\n",
    "    #gets remaining data that are neither under problematic nor unproblematic\n",
    "    \n",
    "    # store index of rows in each problematic_df & unproblematic_df in list\n",
    "    problematic_index_list = list(problematic_df.index.values)\n",
    "    unproblematic_index_list = list(unproblematic_index_list.index.values)\n",
    "    # exlude from df if index in list \n",
    "    df = df.loc[~df.index.isin(df.problematic_index_list)]\n",
    "    df = df.loc[~df.index.isin(df.unproblematic_index_list)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62febeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update df -> when given 2 dfs, \n",
    "# 1 being the original one and \n",
    "# another being a subset of the original but with several rows changed\n",
    "# and there is a need to change rows of the original one with those in the subset\n",
    "\n",
    "def update_df(df_og,df_new):\n",
    "    df_og.update(df_new)\n",
    "    return df_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df vertically aka concatenate\n",
    "\n",
    "def create_frankenstien_col(df1,df2):\n",
    "    df = pd.concat(df1,df2)\n",
    "    #remove last 5 columns\n",
    "    df = df.iloc[:,]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract postal code from address\n",
    "\n",
    "def extract_address(df):\n",
    "    df['postal_extracted1'] = df['address'].str.extract(r\"([S]+\\d{6})\")\n",
    "    df['postal_extracted2'] = df['address'].str.extract(r\"([Singapore ]+\\d{6})\")\n",
    "    df['postal_extracted_f'] = df[['postal_extracted1','postal_extracted2']].agg(' '.join, axis = 1)\n",
    "    df['postal_extracted_f'] = df['postal_extracted_f'].fillna('0')\n",
    "    df.drop([postal_extracted1,postal_extracted2], axis =1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d3850",
   "metadata": {},
   "source": [
    "# Data wranggling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of column\n",
    "# reduce memory usage by changing object to category dtype\n",
    "df.who = df.who.astype('category')\n",
    "df.col = df.who.astype('float')\n",
    "\n",
    "# converts column values to numeric datatype while \n",
    "# the non-numerics invalid values (such as -) will be converted to NaN. \n",
    "# avoids being thrown an error for values like \"-\" \n",
    "\n",
    "df.col_with_numeric_value = pd.to_numeric(df.age,errors = 'coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a009c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new col storing ranking\n",
    "df.rank = pd.Categorical(df.pclass,categories=[3,2,1], ordered = True) # Ascending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unit number, only works if unit number is  in the format \" blah bla #30-74\" \n",
    "#NOT \"blahbla#30-74\"\n",
    "import string\n",
    "\n",
    "def extract_unit(s):\n",
    "    s = ''.join(filter(lambda x:x in string.printable, s))\n",
    "    for element in s.split(\" \"):\n",
    "        if element.startswith(\"#\"):\n",
    "            unit_no = element\n",
    "            \n",
    "        else:\n",
    "            unit_no = \"0\"\n",
    "    return unit_no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column then replace values using a dictionary \n",
    "# making use of the mapping function\n",
    "classes = {'problematic':1, 'mildly':2, 'unproblematic':3}\n",
    "df['class_num'] = df['class'].map(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the map function to multiple columns with applymap\n",
    "mapping = {1:'Yes',0:'No'}\n",
    "cols = ['col1','col2']\n",
    "df[cols] = df[cols].applymap(mapping.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column that codes a numerical value for each categorical value in the column\n",
    "# condition: the index needs to be in running sequence without any number missing\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i,'class'] == 'class_value_1':\n",
    "        df.loc[i,'class_value_1'] = 1\n",
    "    elif df.loc[i,'class'] == 'class_value_2':\n",
    "        df.loc[i,'class_value_2'] = 2\n",
    "    elif df.loc[i,'class'] == 'class_value_3':\n",
    "        df.loc[i,'class_value_3'] = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a3809",
   "metadata": {},
   "source": [
    "# Data Analysis & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1de887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line graph\n",
    "df.plot(x='independent', y='dependent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "df.numerical_continuous.plot('hist')\n",
    "df.numerical_continuous.plot('hist', bins = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ae3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale with log scales\n",
    "df.numerical_continuous.plot(kind='hist', rot=70, logx=True, logy=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability density function - to modify template\n",
    "mu = 200\n",
    "sigma = 15\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma)\n",
    "plt.plot(x, st.norm.pdf(x, mu, sigma))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boxplots and set the y-axis limits\n",
    "df.boxplot(column='numerical_continuous', by='categorical1').set_ylim(0,100)\n",
    "df.boxplot(column='numerical_continuous', by='categorical1', rot=90) # rotates x axis labels\n",
    "df.boxplot(column = ['numerical_continuous','categorical1','categorical2']) # selected columns only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating scatterplot\n",
    "df.plot(kind='scatter', x='independent', y='dependent', rot=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse z-score\n",
    "from scipy.stats import zscore \n",
    "\n",
    "numerical_zscore = zscore(df.fare)\n",
    "df.numerical_zscore = numerical_zscore \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af256837",
   "metadata": {},
   "source": [
    "# One Map Api\n",
    "\n",
    "Codes to retrive postal codes for each address in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e030efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    return df\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = load_data(csv)\n",
    "#csv = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7481bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postal_code_from_one_map(address):\n",
    "    error = \"cannot be found\"\n",
    "    try:\n",
    "        req = requests.get('https://developers.onemap.sg/commonapi/search?searchVal='+address+'&returnGeom=Y&getAddrDetails=Y&pageNum=1')\n",
    "        resultsdict = eval(req.text)\n",
    "        output = resultsdict['results'][0]['POSTAL']\n",
    "        if output != 'NIL':\n",
    "            return str(output)\n",
    "        else:\n",
    "            #next match for in results df \n",
    "            return resultsdict['results'][1]['POSTAL']\n",
    "\n",
    "    except:\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['poco'] = df['address'].apply(lambda x: get_postal_code_from_one_map(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
